# Лабораторная работа по PySpark

# Apache Spark Labs — Data Engineering

Репозиторий содержит две лабораторные работы, выполненные с использованием Apache Spark, PostgreSQL, Kafka, Cassandra, Flask и других инструментов.

## Лабораторная работа 1 — Генерация и загрузка заказов

Полный пайплайн для имитации обработки заказов из кафе и ресторанов:

- генерация заказов с ошибками и запись в CSV (~100 МБ)
- фильтрация данных, экспорт в Avro и Parquet (с партиционированием по дате и городу)
- загрузка в PostgreSQL: в виде схемы 3НФ и денормализованной схемы "звезда"
- агрегация заказов и запись в MongoDB

Файлы: `01_generate_orders.py`, `02_process_orders.py`, `03_load_to_postgres_3nf.py`, `04_load_to_postgres_star.py`, `05_aggregate_to_mongodb.py`

## Лабораторная работа 2 — Web API и потоковая передача данных

Платформа, реализующая приём, хранение и передачу данных:

- Web API на Flask для записи/чтения сущностей в PostgreSQL
- выгрузка новых данных в JSON-файлы каждую минуту
- (в следующих этапах: стриминг через Spark, Kafka и запись в Cassandra)

Файл: `web_api_service.py`

## Контекст

Репозиторий может использоваться в качестве демонстрации навыков в области обработки данных, построения пайплайнов и работы с современным стеком data engineering.
